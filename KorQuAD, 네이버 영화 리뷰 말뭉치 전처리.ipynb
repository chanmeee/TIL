{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KorQuAD \n",
    "- KORQuAD는 한국어 기계 독해를 위한 데이터셋이다.\n",
    "- LG CNS가 구축해 2018년 공개했으며 학습/데브/테스트셋을 모두 포함해 7만 79건에 이르는 방대한 데이터다. 한국어 위키백과의 '알찬 글', '좋은 글' 등 양질의 문서를 수집해 이 가운데 일부 문단으로부터 파생될 수 있는 질문과 답변 쌍을 사람들이 직접 만들었다.\n",
    "- 구축 전 과정에 사람들이 직접 개입했고 그 검증 역시 철저한 것으로 유명하다. 이 때문에 한국어 임베딩용 말뭉치로 손색이 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 코드 \n",
    "\n",
    "import json\n",
    "\n",
    "corpus_fname = '/notebooks/embedding/data/raw/KorQuAD_v1.0_train.json'\n",
    "output_fname = '/notebooks/embedding/data/processed_korquad_train.txt'\n",
    "\n",
    "with open(corpus_fname) as f1, open(output_name, 'w', encoding='utf-8') as f2:\n",
    "    dataset_json = json.load(f1)\n",
    "    dataset = dataset_json['data']\n",
    "    for article in dataset:\n",
    "        w_lines = []\n",
    "        for paragraph in article['paragraphs']:\n",
    "            w_lines.append(paragraph['context']) # context 부분 w_lines에 붙이기 \n",
    "            for qa in paragraph['qas']:\n",
    "                q_text = qa['question'] # 질문 텍스트   \n",
    "                for a in qa['answers']: \n",
    "                    a_text = a['text'] # 답변 텍스트 \n",
    "                    w_lines.append(q_text + \" \" + a_text) # 질문 텍스트와 답변 텍스트를 합쳐 w_lines에 붙이기  \n",
    "        for line in w_lines:\n",
    "            f2.writelines(line + '\\n')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화 리뷰 말뭉치 \n",
    "- 네이버 영화 리뷰 말뭉치는 네이버 영화 페이지의 영화 리뷰들을 평점과 함께 수록한 한국어 말뭉치이다.\n",
    "- 박은정 님께서 구축하고 정제해 공개한 말뭉치로 **감성 분석**이나 **문서 분류** 태스크 수행에 제격인 데이터셋이다.\n",
    "- 레코드 하나는 문서(리뷰)에 대응한다. **문서 ID, 문서 내용, 레이블(긍정 1, 부정 0)로 구성**돼 있으며 각 열은 **탭 문자로 구분**돼 있다. 데이터의 절반이 긍정, 나머지 절반이 부정 레이블이 달린 문서이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 코드 \n",
    "\n",
    "corpus_path = '/notebooks/embedding/data/raw/rating.txt'\n",
    "output_fname = '/notebooks/embedding/data/processed/processed_ratings.txt'\n",
    "with_label = False  # 레이블과 함께 저장하고 싶으면 with_label = True로 설정 \n",
    "\n",
    "with open(corpus_path, 'r', encoding='utf-8') as f1, \\\n",
    "        open(output_fname, 'w', encoding='utf-8') as f2:\n",
    "    next(f1)  # skip head line\n",
    "    for line in f1:\n",
    "        _, sentence, label = line.strip().split('\\t') \n",
    "        if not sentence: continue\n",
    "        if with_label: \n",
    "            f2.writelines(sentence + '\\u241E' + label + '\\n') # \\u241E\n",
    "        else:\n",
    "            f2.writelines(sentence + '\\n') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
